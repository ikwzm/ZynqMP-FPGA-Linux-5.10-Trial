diff --git a/drivers/gpu/drm/Kconfig b/drivers/gpu/drm/Kconfig
index ca868271f..5bfcc8164 100644
--- a/drivers/gpu/drm/Kconfig
+++ b/drivers/gpu/drm/Kconfig
@@ -211,6 +211,12 @@ config DRM_GEM_CMA_HELPER
 	help
 	  Choose this if you need the GEM CMA helper functions
 
+config DRM_GEM_CACMA_HELPER
+	bool
+	depends on DRM
+	help
+	  Choose this if you need the GEM CACMA(Cache-Able CMA) helper functions
+
 config DRM_KMS_CMA_HELPER
 	bool
 	depends on DRM
diff --git a/drivers/gpu/drm/Makefile b/drivers/gpu/drm/Makefile
index 81569009f..5faac9e9a 100644
--- a/drivers/gpu/drm/Makefile
+++ b/drivers/gpu/drm/Makefile
@@ -25,6 +25,7 @@ drm-$(CONFIG_DRM_LIB_RANDOM) += lib/drm_random.o
 drm-$(CONFIG_DRM_VM) += drm_vm.o
 drm-$(CONFIG_COMPAT) += drm_ioc32.o
 drm-$(CONFIG_DRM_GEM_CMA_HELPER) += drm_gem_cma_helper.o
+drm-$(CONFIG_DRM_GEM_CACMA_HELPER) += drm_gem_cacma_helper.o
 drm-$(CONFIG_DRM_GEM_SHMEM_HELPER) += drm_gem_shmem_helper.o
 drm-$(CONFIG_DRM_PANEL) += drm_panel.o
 drm-$(CONFIG_OF) += drm_of.o
diff --git a/drivers/gpu/drm/drm_gem_cacma_helper.c b/drivers/gpu/drm/drm_gem_cacma_helper.c
new file mode 100644
index 000000000..043f3d551
--- /dev/null
+++ b/drivers/gpu/drm/drm_gem_cacma_helper.c
@@ -0,0 +1,549 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright 2022 Ichiro.Kawazome
+ */
+#include <linux/dma-buf.h>
+#include <linux/dma-mapping.h>
+#include <linux/export.h>
+#include <linux/mm.h>
+#include <linux/mutex.h>
+#include <linux/slab.h>
+
+#include <drm/drm.h>
+#include <drm/drm_device.h>
+#include <drm/drm_drv.h>
+#include <drm/drm_gem_cacma_helper.h>
+#include <drm/drm_vma_manager.h>
+#include <drm/drm_ioctl.h>
+#include <drm/drm_gem.h>
+
+/**
+ * DOC: cacma helpers
+ *
+ * The Contiguous Memory Allocator reserves a pool of memory at early boot
+ * that is used to service requests for large blocks of contiguous memory.
+ *
+ * The DRM GEM CACMA helpers use this allocator as a means to provide buffer
+ * objects that are physically contiguous in memory. This is useful for
+ * display drivers that are unable to map scattered buffers via an IOMMU.
+ */
+
+/**
+ * struct drm_gem_cacma_object - GEM object backed by CMA memory allocations
+ * @base:   base GEM object
+ * @paddr:  physical address of the backing memory
+ * @vaddr:  kernel virtual address of the backing memory
+ * @size:   size of the backing memory
+ * @sgt:    scatter/gather table for imported PRIME buffers. 
+ *          The table can have more than one entry but they are guaranteed to 
+ *          have contiguous DMA addresses.
+ * @cached: map object cached (instead of using writecombine).
+ */
+struct drm_gem_cacma_object {
+	struct drm_gem_object   base;
+	dma_addr_t              paddr;
+	void*                   vaddr;
+	size_t                  size;
+	struct sg_table*        sgt;
+	bool                    cached;
+};
+
+#define to_drm_gem_cacma_object(gem_obj) \
+	container_of(gem_obj, struct drm_gem_cacma_object, base)
+
+/**
+ * __drm_gem_cacma_create() - Create a CACMA-GEM object without allocating memory
+ * @drm: DRM device
+ * @size: size of the object to allocate
+ *
+ * This function creates and initializes a CACMA-GEM object of the given size,
+ * but doesn't allocate any memory to back the object.
+ *
+ * Returns:
+ * A struct drm_gem_cma_object* on success or an ERR_PTR()-encoded negative
+ * error code on failure.
+ */
+static struct drm_gem_cacma_object *
+__drm_gem_cacma_create(struct drm_device *drm, size_t size)
+{
+	struct drm_gem_cacma_object* cma_obj;
+	struct drm_gem_object*       gem_obj;
+	int ret;
+
+	if (drm->driver->gem_create_object)
+		gem_obj = drm->driver->gem_create_object(drm, size);
+	else
+		gem_obj = kzalloc(sizeof(*cma_obj), GFP_KERNEL);
+
+	if (!gem_obj)
+		return ERR_PTR(-ENOMEM);
+
+	ret = drm_gem_object_init(drm, gem_obj, size);
+	if (ret)
+		goto error;
+
+	ret = drm_gem_create_mmap_offset(gem_obj);
+	if (ret) {
+		drm_gem_object_release(gem_obj);
+		goto error;
+	}
+
+	cma_obj = to_drm_gem_cacma_object(gem_obj);
+	cma_obj->paddr  = (dma_addr_t)NULL;
+	cma_obj->vaddr  = NULL;
+	cma_obj->size   = 0;
+	cma_obj->cached = 0;
+	
+	return cma_obj;
+
+error:
+	kfree(cma_obj);
+	return ERR_PTR(ret);
+}
+
+/**
+ * drm_gem_cacma_create() - allocate a CACMA-GEM object with the given size
+ * @drm: DRM device
+ * @size: size of the object to allocate
+ * @cache: cache mode
+ *
+ * This function creates a CACMA-GEM object and allocates a contiguous chunk of
+ * memory as backing store. The backing memory has the writecombine attribute
+ * set.
+ *
+ * Returns:
+ * A struct drm_gem_object * on success or an ERR_PTR()-encoded negative
+ * error code on failure.
+ */
+struct drm_gem_object*
+drm_gem_cacma_create(struct drm_device *drm, size_t size, bool cache)
+{
+	struct drm_gem_cacma_object* cma_obj;
+	struct drm_gem_object*       gem_obj;
+	void*                        vaddr;
+	dma_addr_t                   paddr;
+	int                          ret;
+
+	size = round_up(size, PAGE_SIZE);
+
+	cma_obj = __drm_gem_cacma_create(drm, size);
+	if (IS_ERR(cma_obj))
+		return ERR_CAST(cma_obj);
+
+	gem_obj = &cma_obj->base;
+
+	if (cache)
+		vaddr = dma_alloc_coherent(drm->dev, size, &paddr, GFP_KERNEL | __GFP_NOWARN);
+	else
+		vaddr = dma_alloc_wc(      drm->dev, size, &paddr, GFP_KERNEL | __GFP_NOWARN);
+	
+	if (IS_ERR_OR_NULL(vaddr)) {
+		ret = (IS_ERR(vaddr)) ? PTR_ERR(vaddr) : -ENOMEM;
+		DRM_DEBUG("failed to allocate buffer with size %zu\n", size);
+		goto error;
+	}
+
+	cma_obj->paddr  = paddr;
+	cma_obj->vaddr  = vaddr;
+	cma_obj->size   = size;
+	cma_obj->cached = cache;
+
+	return gem_obj;
+
+error:
+	drm_gem_object_put(gem_obj);
+	return ERR_PTR(ret);
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_create);
+
+/**
+ * drm_gem_cacma_create_with_handle - allocate a CACMA-GEM object with the given
+ *      size and return a GEM handle to it
+ * @file_priv: DRM file-private structure to register the handle for
+ * @drm: DRM device
+ * @size: size of the object to allocate
+ * @cache: cache mode
+ * @handle: return location for the GEM handle
+ *
+ * This function creates a CACMA-GEM object, allocating a physically contiguous
+ * chunk of memory as backing store. The GEM object is then added to the list
+ * of object associated with the given file and a handle to it is returned.
+ *
+ * Returns:
+ * A struct drm_gem_object * on success or an ERR_PTR()-encoded negative
+ * error code on failure.
+ */
+struct drm_gem_object*
+drm_gem_cacma_create_with_handle(struct drm_file *file_priv,
+				 struct drm_device *drm, size_t size, bool cache,
+				 uint32_t *handle)
+{
+	struct drm_gem_object* gem_obj;
+	int ret;
+
+	gem_obj = drm_gem_cacma_create(drm, size, cache);
+	if (IS_ERR(gem_obj))
+		return ERR_CAST(gem_obj);
+
+	/*
+	 * allocate a id of idr table where the obj is registered
+	 * and handle has the id what user can see.
+	 */
+	ret = drm_gem_handle_create(file_priv, gem_obj, handle);
+	/* drop reference from allocate - handle holds it now. */
+	drm_gem_object_put(gem_obj);
+	if (ret)
+		return ERR_PTR(ret);
+
+	return gem_obj;
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_create_with_handle);
+
+/**
+ * drm_gem_cacma_free_object - free resources associated with a CACMA-GEM object
+ * @gem_obj: GEM object to free
+ *
+ * This function frees the backing memory of the CMA GEM object, cleans up the
+ * GEM object state and frees the memory used to store the object itself.
+ * If the buffer is imported and the virtual address is set, it is released.
+ * Drivers using the CMA helpers should set this as their
+ * &drm_driver.gem_free_object_unlocked callback.
+ */
+void
+drm_gem_cacma_free_object(struct drm_gem_object *gem_obj)
+{
+	struct drm_gem_cacma_object* cma_obj;
+
+	cma_obj = to_drm_gem_cacma_object(gem_obj);
+
+	if (gem_obj->import_attach) {
+		if (cma_obj->vaddr) {
+			dma_buf_vunmap(gem_obj->import_attach->dmabuf, cma_obj->vaddr);
+			cma_obj->vaddr = NULL;
+		}
+		drm_prime_gem_destroy(gem_obj, cma_obj->sgt);
+	} else {
+		if (cma_obj->vaddr) {
+			struct device* dev   = gem_obj->dev->dev;
+			size_t         size  = cma_obj->size;
+			void*          vaddr = cma_obj->vaddr;
+			dma_addr_t     paddr = cma_obj->paddr;
+			if (cma_obj->cached)
+				dma_free_coherent(dev, size, vaddr, paddr);
+			else
+				dma_free_wc(      dev, size, vaddr, paddr);
+			cma_obj->vaddr = NULL;
+		}
+	}
+
+	drm_gem_object_release(gem_obj);
+
+	kfree(cma_obj);
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_free_object);
+
+/**
+ * drm_gem_cacma_vm_fault() - CACMA-GEM object vm area fault operation.
+ * @vfm:        Pointer to the vm fault structure.
+ * Return:      VM_FAULT_RETURN_TYPE (Success(=0) or error status(!=0)).
+ */
+static vm_fault_t
+drm_gem_cacma_vm_fault(struct vm_fault *vmf)
+{
+	struct vm_area_struct*       vma     = vmf->vma;
+	struct drm_gem_object*       gem_obj = vma->vm_private_data;
+	struct drm_gem_cacma_object* cma_obj = to_drm_gem_cacma_object(gem_obj);
+	unsigned long offset                 = vmf->address - vma->vm_start;
+	unsigned long virt_addr              = vmf->address;
+	unsigned long phys_addr              = cma_obj->paddr + offset;
+	unsigned long page_frame_num         = phys_addr  >> PAGE_SHIFT;
+	unsigned long request_size           = 1          << PAGE_SHIFT;
+	unsigned long available_size         = cma_obj->size  - offset;
+
+	if (request_size > available_size)
+	        return VM_FAULT_SIGBUS;
+
+	if (!pfn_valid(page_frame_num))
+	        return VM_FAULT_SIGBUS;
+
+	return vmf_insert_pfn(vma, virt_addr, page_frame_num);
+}
+
+/**
+ * CACMA-GEM object vm operation table.
+ */
+const struct vm_operations_struct drm_gem_cacma_vm_ops = {
+	.fault = drm_gem_cacma_vm_fault,
+	.open  = drm_gem_vm_open,
+	.close = drm_gem_vm_close,
+};
+
+/**
+ * __drm_gem_cacma_mmap() - memory-map a CACMA-GEM object
+ * @gem_obj: GEM object
+ * @vma: VMA for the area to be mapped
+ *
+ * Returns:
+ * 0 on success.
+ */
+static int
+__drm_gem_cacma_mmap(struct drm_gem_object *gem_obj, struct vm_area_struct *vma)
+{
+	struct drm_gem_cacma_object* cma_obj = to_drm_gem_cacma_object(gem_obj);
+
+        vma->vm_flags |= VM_IO | VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP;
+	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+	if (!cma_obj->cached)
+        	vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
+	vma->vm_ops = &drm_gem_cacma_vm_ops;
+	return 0;
+}
+
+/**
+ * drm_gem_cacma_file_mmap() - memory-map a CACMA-GEM object by file operation.
+ * @filp: file object
+ * @vma: VMA for the area to be mapped
+ *
+ * Returns:
+ * 0 on success or a negative error code on failure.
+ */
+int
+drm_gem_cacma_file_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	struct drm_gem_object  *gem_obj;
+	int ret;
+
+	ret = drm_gem_mmap(filp, vma);
+	if (ret)
+		return ret;
+
+	gem_obj  = vma->vm_private_data;
+
+	return __drm_gem_cacma_mmap(gem_obj, vma);
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_file_mmap);
+
+/**
+ * drm_gem_cacma_prime_mmap() - memory-map a CACMA-GEM object by prime operation.
+ * @obj: GEM object
+ * @vma: VMA for the area to be mapped
+ *
+ * Returns:
+ * 0 on success or a negative error code on failure.
+ */
+int
+drm_gem_cacma_prime_mmap(struct drm_gem_object *gem_obj, struct vm_area_struct *vma)
+{
+	int ret;
+
+	ret = drm_gem_mmap_obj(gem_obj, gem_obj->size, vma);
+	if (ret < 0)
+		return ret;
+
+	return __drm_gem_cacma_mmap(gem_obj, vma);
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_prime_mmap);
+
+/**
+ * drm_gem_cacma_print_info() - Print CACMA-GEM Object info for debugfs
+ * @p: DRM printer
+ * @indent: Tab indentation level
+ * @obj: GEM object
+ *
+ * This function can be used as the &drm_driver->gem_print_info callback.
+ * It prints paddr and vaddr for use in e.g. debugfs output.
+ */
+void
+drm_gem_cacma_print_info(struct drm_printer *p,
+			 unsigned int indent,
+			 const struct drm_gem_object *obj)
+{
+	struct drm_gem_cacma_object* cma_obj = to_drm_gem_cacma_object(obj);
+
+	drm_printf_indent(p, indent, "paddr=%pad\n", &cma_obj->paddr);
+	drm_printf_indent(p, indent, "vaddr=%p\n"  ,  cma_obj->vaddr);
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_print_info);
+
+/**
+ * drm_gem_cacma_prime_get_sg_table() - provide a scatter/gather table of pinned
+ *     pages for a CACMA-GEM object
+ * @gem_obj: GEM object
+ *
+ * This function exports a scatter/gather table suitable for PRIME usage by
+ * calling the standard DMA mapping API. 
+ *
+ * Returns:
+ * A pointer to the scatter/gather table of pinned pages or NULL on failure.
+ */
+struct sg_table*
+drm_gem_cacma_prime_get_sg_table(struct drm_gem_object *gem_obj)
+{
+	struct drm_gem_cacma_object* cma_obj = to_drm_gem_cacma_object(gem_obj);
+	struct sg_table*             sgt;
+	int ret;
+
+	sgt = kzalloc(sizeof(*sgt), GFP_KERNEL);
+	if (!sgt)
+		return ERR_PTR(-ENOMEM);
+
+	ret = dma_get_sgtable(
+		gem_obj->dev->dev, /* struct device*   dev      */
+		sgt              , /* struct sg_table* sgt      */
+		cma_obj->vaddr   , /* void*            cpu_addr */
+		cma_obj->paddr   , /* dma_addr_t       dma_addr */
+		gem_obj->size      /* size_t           size     */
+	      );
+	if (ret < 0)
+		goto out;
+
+	return sgt;
+
+out:
+	kfree(sgt);
+	return ERR_PTR(ret);
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_prime_get_sg_table);
+
+/**
+ * drm_gem_cacma_prime_import_sg_table() - produce a CACMA-GEM object from another
+ *     driver's scatter/gather table of pinned pages
+ * @dev: device to import into
+ * @attach: DMA-BUF attachment
+ * @sgt: scatter/gather table of pinned pages
+ *
+ * This function imports a scatter/gather table exported via DMA-BUF by
+ * another driver. Imported buffers must be physically contiguous in memory
+ * (i.e. the scatter/gather table must contain a single entry). Drivers that
+ * use the CMA helpers should set this as their
+ * &drm_driver.gem_prime_import_sg_table callback.
+ *
+ * Returns:
+ * A pointer to a newly created GEM object or an ERR_PTR-encoded negative
+ * error code on failure.
+ */
+struct drm_gem_object *
+drm_gem_cacma_prime_import_sg_table(struct drm_device *dev,
+				    struct dma_buf_attachment *attach,
+				    struct sg_table *sgt)
+{
+	struct drm_gem_cacma_object* cma_obj;
+
+	/* check if the entries in the sg_table are contiguous */
+	if (drm_prime_get_contiguous_size(sgt) < attach->dmabuf->size)
+		return ERR_PTR(-EINVAL);
+
+	/* Create a CACMA-GEM Object. */
+	cma_obj = __drm_gem_cacma_create(dev, attach->dmabuf->size);
+	if (IS_ERR(cma_obj))
+		return ERR_CAST(cma_obj);
+
+	cma_obj->paddr = sg_dma_address(sgt->sgl);
+	cma_obj->sgt   = sgt;
+
+	DRM_DEBUG_PRIME("dma_addr = %pad, size = %zu\n", &cma_obj->paddr, attach->dmabuf->size);
+
+	return &cma_obj->base;
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_prime_import_sg_table);
+
+/**
+ * drm_gem_cacma_prime_import_sg_table_vmap() - PRIME import another driver's
+ *	scatter/gather table and get the virtual address of the buffer
+ * @dev: DRM device
+ * @attach: DMA-BUF attachment
+ * @sgt: Scatter/gather table of pinned pages
+ *
+ * This function imports a scatter/gather table using
+ * drm_gem_cma_prime_import_sg_table() and uses dma_buf_vmap() to get the kernel
+ * virtual address. This ensures that a CMA GEM object always has its virtual
+ * address set. This address is released when the object is freed.
+ *
+ * This function can be used as the &drm_driver.gem_prime_import_sg_table
+ * callback. The &DRM_GEM_CMA_DRIVER_OPS_VMAP macro provides a shortcut to set
+ * the necessary DRM driver operations.
+ *
+ * Returns:
+ * A pointer to a newly created GEM object or an ERR_PTR-encoded negative
+ * error code on failure.
+ */
+struct drm_gem_object *
+drm_gem_cacma_prime_import_sg_table_vmap(struct drm_device *dev,
+				         struct dma_buf_attachment *attach,
+				         struct sg_table *sgt)
+{
+	struct drm_gem_cacma_object* cma_obj;
+	struct drm_gem_object*       gem_obj;
+	void *vaddr;
+
+	vaddr = dma_buf_vmap(attach->dmabuf);
+	if (!vaddr) {
+		DRM_ERROR("Failed to vmap PRIME buffer\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	gem_obj = drm_gem_cacma_prime_import_sg_table(dev, attach, sgt);
+	if (IS_ERR(gem_obj)) {
+		dma_buf_vunmap(attach->dmabuf, vaddr);
+		return gem_obj;
+	}
+
+	cma_obj = to_drm_gem_cacma_object(gem_obj);
+	cma_obj->vaddr = vaddr;
+
+	return gem_obj;
+}
+EXPORT_SYMBOL(drm_gem_cacma_prime_import_sg_table_vmap);
+
+/**
+ * drm_gem_cacma_prime_vmap() - map a CACMA-GEM object into the kernel's virtual
+ *     address space
+ * @gem_obj: GEM object
+ *
+ * This function maps a buffer exported via DRM PRIME into the kernel's
+ * virtual address space. Since the CMA buffers are already mapped into the
+ * kernel virtual address space this simply returns the cached virtual
+ * address. 
+ *
+ * Returns:
+ * The kernel virtual address of the CACMA-GEM object's backing store.
+ */
+void*
+drm_gem_cacma_prime_vmap(struct drm_gem_object *gem_obj)
+{
+	struct drm_gem_cacma_object* cma_obj = to_drm_gem_cacma_object(gem_obj);
+
+	return cma_obj->vaddr;
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_prime_vmap);
+	
+/**
+ * drm_gem_cacma_prime_vunmap() - unmap a CACMA-GEM object from the kernel's virtual
+ *     address space
+ * @gem_obj: GEM object
+ * @vaddr: kernel virtual address where the CMA GEM object was mapped
+ *
+ * This function removes a buffer exported via DRM PRIME from the kernel's
+ * virtual address space. This is a no-op because CMA buffers cannot be
+ * unmapped from kernel space. 
+ */
+void
+drm_gem_cacma_prime_vunmap(struct drm_gem_object *gem_obj, void *vaddr)
+{
+	/* Nothing to do */
+}
+EXPORT_SYMBOL_GPL(drm_gem_cacma_prime_vunmap);
+
+/**
+ * CACMA-GEM object function table.
+ */
+static const struct drm_gem_object_funcs drm_gem_cacma_funcs = {
+    	.free         = drm_gem_cacma_free_object, 
+    	.print_info   = drm_gem_cacma_print_info, 
+    	.get_sg_table = drm_gem_cacma_prime_get_sg_table,
+    	.vmap         = drm_gem_cacma_prime_vmap,
+    	.vunmap       = drm_gem_cacma_prime_vunmap,
+	.vm_ops       = &drm_gem_cacma_vm_ops,
+    /* 	.mmap         = drm_gem_cacma_mmap, */
+};
+
diff --git a/include/drm/drm_gem_cacma_helper.h b/include/drm/drm_gem_cacma_helper.h
new file mode 100644
index 000000000..f6b462f88
--- /dev/null
+++ b/include/drm/drm_gem_cacma_helper.h
@@ -0,0 +1,41 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef __DRM_GEM_CACMA_HELPER_H__
+#define __DRM_GEM_CACMA_HELPER_H__
+
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/mutex.h>
+
+#include <drm/drm_gem.h>
+#include <drm/drm_file.h>
+#include <drm/drm_prime.h>
+#include <drm/drm_device.h>
+
+struct dma_buf_attachment;
+struct drm_printer;
+struct sg_table;
+
+struct drm_gem_object* drm_gem_cacma_create(struct drm_device *drm, size_t size, bool cache);
+struct drm_gem_object* drm_gem_cacma_create_with_handle(struct drm_file *file_priv,
+                                            struct drm_device *drm, size_t size, bool cache,
+                                            uint32_t *handle);
+struct drm_gem_object* drm_gem_cacma_prime_import_sg_table(struct drm_device *dev,
+                                            struct dma_buf_attachment *attach,
+                                	    struct sg_table *sgt);
+struct drm_gem_object* drm_gem_cacma_prime_import_sg_table_vmap(struct drm_device *dev,
+                                            struct dma_buf_attachment *attach,
+                                	    struct sg_table *sgt);
+
+void  drm_gem_cacma_free_object(struct drm_gem_object *gem_obj);
+
+struct sg_table* drm_gem_cacma_prime_get_sg_table(struct drm_gem_object *gem_obj);
+
+void* drm_gem_cacma_prime_vmap(struct drm_gem_object *gem_obj);
+void  drm_gem_cacma_prime_vunmap(struct drm_gem_object *gem_obj, void *vaddr);
+int   drm_gem_cacma_prime_mmap(struct drm_gem_object *gem_obj, struct vm_area_struct *vma);
+int   drm_gem_cacma_file_mmap(struct file *filp, struct vm_area_struct *vma);
+void  drm_gem_cacma_print_info(struct drm_printer *p,
+                               unsigned int indent,
+                               const struct drm_gem_object *obj);
+
+#endif /* __DRM_GEM_CACMA_HELPER_H__ */
